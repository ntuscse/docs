---
sidebar_position: 3
---

# AWS S3

AWS Simple Storage Service (S3) is Amazon's Object Storage service that offers high scalability, availability, fault tolerance and performance. S3 can be used to store a 
variety of objects, from hosting static websites and rendering JavaScript/React for the website frontend, to storing data lakes and backup archives. As such, there
are different tiers available which provide different pricing and performance.

![S3 Buckets](https://www.testpreptraining.com/tutorial/wp-content/uploads/2019/08/image008.png)

## Storage Structure

How is data stored under S3? Data is stored under logical units called buckets. Buckets are the basic unit of storage under S3, which means all data must be stored
within a bucket, from entire repositories to a single file. Generally, it is considered good practice to store clustered objects, ie. objects that share a similar
purpose, or the same security configurations, under the same bucket. This is done since there are many security policies that S3 allows users to set on the bucket level,
which restrict access to certain objects under the bucket, and lifecylce policies that faciliate the transfer of data between different tiers(more on this later).
For example, private files, artifacts and other confidential data can be stored under the same bucket which is configured to deny any HTTP requests and configured 
with ACLs(Access Control Lists) which limit the read and write authorizations to a few chosen users within the same AWS Organization. This is not an exhaustive 
list, and rather there are many such policies that can be configured on the bucket level to facilitate Access Management, explained in further detail here
[AWS S# Bucket Policies](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html).

## Storage Classes

Amazon S3 provides different tiers, or storage classes for storing your data. The motivation behind this is that all data is heterogeneous: this means that
different types of data will have different read/write operations, require different availability, and different levels of access. For example, archive backup data
is expected to have a much more infrequent read/write requirement than a static website hosted on S3, and therefore worth compromising on availability for lower
costs.

Specifically, AWS S3 provides trhe following storage classes:

1. S3 Standard: This is the cheapest tier resource for frequently accessed data that requires high availability.
2. S3 Infreqeunt Access: This option is slighgtly cheaper than S3 Standard and perfect for data that is not very frequently accessed, but still requires reliable
availability.
3. S3 Infrequent Access One Zone: S3 buckets are automatically replicated across 3 Availbaility Zones to provide for fault tolerance in the face of data center
failures. However, for less critical data, it is cheaper to use the One Zone tier, which onyl stores the data under the Availability Zone specified.
4. S3 Glacier Deep Archive: This tiering is perfect for archival data that mistly consists of logs, backups etc, which requires very low availbility, high retrieval 
times, and very cheap cost.
5. S3 Intelligent Tiering: This storage class performs tiering automatically by surveying the access times and patterns of different data, and assigning the buckets
to one of the above mentioned tiers, in order to optimize costs.

AMazon S3 fits in well with the AWS Lambda offering using the S3 Batch operations. Depending upon your application, you may want to read up more about S3 Batch
Operations here [S3 Batch Operations](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html).